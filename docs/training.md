
### 3. Tissue Segmentation Model Training  
**Script**: `train.py` (ResNet-based U-Net)

---

#### Purpose  
Train a multi-class semantic segmentation model (epidermis, keratin, background) using cropped H&E images and corresponding mask labels.

---

#### Description  
The `train.py` script implements a complete deep learning pipeline for tissue segmentation based on a ResNet-backed U-Net architecture. The training workflow is fully compatible with the outputs generated by the image cropping pipeline (`data_preprocessing.py`).

---

#### Key Components  

**Configuration**
- Controlled via `base_config.yaml` and `training_config.yaml`
- Parameters include backbone selection, image size, batch size, learning rate, number of classes, and training epochs

**Data Preparation**
- `TrainingLabelCreator` maps RGB mask colors to integer class indices
- `CustomDataGenerator` loads cropped H&E–mask pairs and applies on-the-fly data augmentation:
  - Geometric: flips, rotations, elastic deformations
  - Intensity: contrast and color augmentations

**Model Building**
- U-Net architecture from `segmentation_models` (`sm.Unet`)
- ResNet backbone with optional dropout
- Compiled using Dice + Focal loss
- Adam optimizer for stable convergence

**Training Pipeline (`TrainPipeline`)**
- Handles experiment versioning and continuation logic
- Supports resuming training from checkpoints
- Optional Optuna-based hyperparameter optimization
- Saves comprehensive outputs:
  - Best-performing model
  - Epoch-wise model checkpoints
  - Training curves (CSV + PNG)
  - Sample prediction visualizations
  - Confusion matrix and classification report
  - Metrics summary and per-class performance metrics

---

#### Main CLI Flags  
```bash
--version               experiment identifier
--optuna                run hyperparameter optimization
--optuna-load           continue Optuna study
--continue-training     resume training from checkpoint
````

---

#### Integration with Preprocessing Pipeline

```plaintext
data_preprocessing  →  cropped images and masks
       │
       ▼
train.py            →  segmentation model training
```

The segmentation training workflow is fully compatible with the outputs of the image cropping pipeline.
The HPA database construction (`build_hpa_database.py`) is independent and not directly used during model training.

---

#### Notes / Validation Checks

* Mask encoding must be consistent with `n_classes` defined in `training_config.yaml`
* RGB-to-class mapping should start from index 0 for compatibility with loss functions
* Augmentation strategies are applied in both geometric and color domains; ordering should be verified
* During Optuna trials, `save_models=False` prevents accidental overwriting of trained models
* Versioning and continuation logic (`_cont` suffix, `reuse_last` flag) ensures safe experiment tracking
* GPU memory usage should be monitored when using large backbones (e.g., ResNet152 at 512×512 resolution)

---

#### Methods

A deep learning–based semantic segmentation model was trained using a ResNet-backed U-Net architecture. Cropped H&E images and corresponding mask labels were generated using a semi-automated preprocessing pipeline. RGB mask labels were converted to integer class indices, and on-the-fly data augmentation was applied to improve generalization.

The model was trained using a combination of Dice and Focal loss functions with the Adam optimizer. Training included experiment versioning, optional hyperparameter optimization, and comprehensive logging of model checkpoints, training curves, and performance metrics. This pipeline enables reproducible training and evaluation of multi-class tissue segmentation models.

Here is a **fully updated Markdown section** that captures *all* the technical detail, structure, and publication wording from your Word document, while staying consistent with Sections 1–3.
